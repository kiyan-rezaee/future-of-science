{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac006fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "\n",
    "config_path = os.path.join(\"..\", \"config.yaml\")\n",
    "with open(config_path, \"rt\") as config_file:\n",
    "\tconfig = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('./predictions/full_data.csv')\n",
    "edges_dir = os.path.join(\"..\", \"FOS_Benchmark\", \"_\".join(config[\"DOMAINS\"]), \"edges\")\n",
    "edges = pd.read_csv(os.path.join(edges_dir, \"all_edges.csv\"), header=None, names=[\"src\", \"dst\", \"ts\"])\n",
    "test_start = edges[\"ts\"].quantile(0.85)\n",
    "\n",
    "# Step 1: Split the DataFrame into pre-test_start and test_start-onward\n",
    "pre_test_start = full_df[full_df['ts'] < test_start]\n",
    "from_test_start = full_df[full_df['ts'] >= test_start]\n",
    "\n",
    "# Step 2: Identify unique edges (src, dst pairs)\n",
    "# Create a tuple of (src, dst) for easier comparison\n",
    "full_df['edge'] = full_df[['src', 'dst']].apply(tuple, axis=1)\n",
    "pre_test_start_edges = set(pre_test_start[['src', 'dst']].apply(tuple, axis=1))\n",
    "from_test_start_edges = set(from_test_start[['src', 'dst']].apply(tuple, axis=1))\n",
    "\n",
    "# Step 3: Find edges that are in test_start onward but not in pre-test_start\n",
    "new_edges = from_test_start_edges - pre_test_start_edges\n",
    "\n",
    "from_test_start['edge'] = from_test_start[['src', 'dst']].apply(tuple, axis=1)\n",
    "\n",
    "# Step 4: Filter the DataFrame to keep only rows from test_start onward with new edges\n",
    "result_df = from_test_start[from_test_start['edge'].isin(new_edges)]\n",
    "\n",
    "# Step 5: Drop the temporary 'edge' column if you don't need it\n",
    "result_df = result_df.drop(columns=['edge'])\n",
    "\n",
    "# The resulting DataFrame contains only edges from test_start onward that didn't exist before test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edges = set(result_df[['src', 'dst']].apply(tuple, axis=1))\n",
    "\n",
    "# List to store filtered DataFrames\n",
    "filtered_dfs = []\n",
    "\n",
    "file_pattern = r\"predictions/*_prediction_output.csv.csv\"\n",
    "csv_files = glob.glob(file_pattern)  # Get list of CSV files\n",
    "\n",
    "# Process each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "    # Create a temporary column for (src, dst) tuples\n",
    "    df['edge'] = df[['src_node_id', 'dst_node_id']].apply(tuple, axis=1)\n",
    "    # Filter rows where the edge is in result_edges\n",
    "    filtered_df = df[df['edge'].isin(result_edges)]\n",
    "       \n",
    "    # Drop the temporary edge column\n",
    "    filtered_df = filtered_df.drop(columns=['edge'])\n",
    "    # Append to the list of filtered DataFrames\n",
    "    filtered_dfs.append(filtered_df)\n",
    "    \n",
    "# Combine all filtered DataFrames into a single DataFrame\n",
    "final_df = pd.concat(filtered_dfs, ignore_index=True) if filtered_dfs else pd.DataFrame()\n",
    "\n",
    "# final_df now contains all rows from the CSV files where (src, dst) pairs are in result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a581b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = pd.read_csv(\"predictons/threshold.csv\").values.flatten()[0]\n",
    "final_df = final_df[final_df['predict'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2id = pd.read_csv(\"node_id_mapping.csv\").to_dict()\n",
    "final_df[\"src_node_id\"] = final_df[\"src_node_id\"].map(idx2id['node_id'])\n",
    "final_df[\"dst_node_id\"] = final_df[\"dst_node_id\"].map(idx2id['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88745b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d24f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_nodes = {}\n",
    "for field in config[\"DOMAINS\"]:\n",
    "\tfield_nodes[field] = set(pd.read_csv(f\"../OpenAlex_Knowledge_Graph/nodes/{field}.csv\").values.flatten())\n",
    "nodes = set.union(*list(field_nodes.values()))\n",
    "\n",
    "def domain(node):\n",
    "    for field, nodes_field in field_nodes.items():\n",
    "        if node in nodes_field:\n",
    "            return field\n",
    "\n",
    "edge_list = []\n",
    "for _, row in final_df.iterrows():\n",
    "    index1 = row[\"src_node_id\"]\n",
    "    index2 = row[\"dst_node_id\"]\n",
    "    if index1 in nodes and index2 in nodes:\n",
    "        if domain(index1) != domain(index2):\n",
    "            edge_list.append({\"source\": index1, \"destination\": index2, \"pred\": row[\"predict\"]})\n",
    "    else:\n",
    "        print(\"warning\", index1, index2)\n",
    "\n",
    "new_df = pd.DataFrame(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c974e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by pred (ascending)\n",
    "new_df = new_df.sort_values(by=\"pred\", ascending=False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = new_df['source'].values\n",
    "destination = new_df['destination'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.openalex.org/works\"\n",
    "all_results = []  # To store all results\n",
    "counts = []       # To store meta counts\n",
    "\n",
    "for i in range(len(source)):\n",
    "    src = source[i]\n",
    "    dst = destination[i]\n",
    "\n",
    "    params = {\n",
    "        \"filter\": f\"concepts.id:{src},concepts.id:{dst}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send a GET request to the OpenAlex API\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "\n",
    "        data = response.json()  # Parse JSON response\n",
    "\n",
    "        # Append results to all_results\n",
    "        all_results.extend(data.get('results', []))\n",
    "        # Append count to counts list\n",
    "        counts.append(data.get('meta', {}).get('count', 0))\n",
    "\n",
    "        print(f\"Request {i+1}: {data.get('meta', {}).get('count', 0)} results\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request {i+1} failed: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to parse JSON for request {i+1}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing expected data in response for request {i+1}: {e}\")\n",
    "\n",
    "# Save all results into a JSON file\n",
    "with open(f\"{'_'.join(config[\"DOMAINS\"])}_OpenAlex_Results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"All results have been saved to '{'_'.join(config[\"DOMAINS\"])}_OpenAlex_Results.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['counts'] = counts\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc60a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(f\"{'_'.join(config[\"DOMAINS\"])}_discussion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
